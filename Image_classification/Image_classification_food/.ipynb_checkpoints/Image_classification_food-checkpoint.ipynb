{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVwA8MUcj_R-"
   },
   "source": [
    "# Challenge 1: Classification\n",
    "In this challenge, you're given a food classification dataset which has 101 classes. You need to analyze and preprocess the dataset as well as build deep learning models for performing food classification. \n",
    "<br>\n",
    "Three models are to be trained for this task, mainly light, medium, and heavy model. <br>\n",
    "Examples: <br>\n",
    "Light model - mobilenetv2 <br>\n",
    "Medium model - Resnet50 <br>\n",
    "Heavy model - VGG19 <br>\n",
    "<br>\n",
    "The above given models are examples. You are free to choose any deep learning model to train. \n",
    "\n",
    "**Main Objective**:\n",
    "You are supposed to use both TensorFlow and PyTorch for this task. You need to train one model for each framework. (You can use one of the frameworks again for the third model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMkf4SnEkI0y"
   },
   "source": [
    "## Summary \n",
    "\n",
    "Create a table for your train and test accuracy as well as speed for each model (mention the framework used for training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DaKuYJOkOzy"
   },
   "source": [
    "# Analyze the dataset\n",
    "## Objectives\n",
    "1. Upload the dataset provided (Google Drive link). \n",
    "2. Extract the dataset. \n",
    "3. Re-arrange dataset into training and testing folders. \n",
    "4. List number of samples in training and testing folders. \n",
    "5. Plot sample images from training and testing datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uI9EfBkFkP4B"
   },
   "source": [
    "### Your Response/Notes\n",
    "\n",
    "You can summarize your work for this section here/give any explanations if required. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dguXuEjykbbA"
   },
   "source": [
    "**Re-arranging dataset into folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JLq-40A0c8DW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "from glob import iglob\n",
    "from copy import deepcopy\n",
    "\n",
    "import PIL\n",
    "import PIL.ImageOps\n",
    "import PIL.ImageEnhance\n",
    "import PIL.ImageDraw\n",
    "from PIL import Image\n",
    "\n",
    "from audioop import bias\n",
    "\n",
    "import torch\n",
    "from torch.cuda import amp\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_root = 'data/food/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0upqQsZy2ji4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train churros 1/101 completed\n",
      "Train hot_and_sour_soup 2/101 completed\n",
      "Train samosa 3/101 completed\n",
      "Train sashimi 4/101 completed\n",
      "Train pork_chop 5/101 completed\n",
      "Train spring_rolls 6/101 completed\n",
      "Train panna_cotta 7/101 completed\n",
      "Train beef_tartare 8/101 completed\n",
      "Train greek_salad 9/101 completed\n",
      "Train foie_gras 10/101 completed\n",
      "Train tacos 11/101 completed\n",
      "Train pad_thai 12/101 completed\n",
      "Train poutine 13/101 completed\n",
      "Train ramen 14/101 completed\n",
      "Train pulled_pork_sandwich 15/101 completed\n",
      "Train bibimbap 16/101 completed\n",
      "Train beignets 17/101 completed\n",
      "Train apple_pie 18/101 completed\n",
      "Train crab_cakes 19/101 completed\n",
      "Train risotto 20/101 completed\n",
      "Train paella 21/101 completed\n",
      "Train steak 22/101 completed\n",
      "Train baby_back_ribs 23/101 completed\n",
      "Train miso_soup 24/101 completed\n",
      "Train frozen_yogurt 25/101 completed\n",
      "Train club_sandwich 26/101 completed\n",
      "Train carrot_cake 27/101 completed\n",
      "Train falafel 28/101 completed\n",
      "Train bread_pudding 29/101 completed\n",
      "Train chicken_wings 30/101 completed\n",
      "Train gnocchi 31/101 completed\n",
      "Train caprese_salad 32/101 completed\n",
      "Train creme_brulee 33/101 completed\n",
      "Train escargots 34/101 completed\n",
      "Train chocolate_cake 35/101 completed\n",
      "Train tiramisu 36/101 completed\n",
      "Train spaghetti_bolognese 37/101 completed\n",
      "Train mussels 38/101 completed\n",
      "Train scallops 39/101 completed\n",
      "Train baklava 40/101 completed\n",
      "Train edamame 41/101 completed\n",
      "Train macaroni_and_cheese 42/101 completed\n",
      "Train pancakes 43/101 completed\n",
      "Train garlic_bread 44/101 completed\n",
      "Train beet_salad 45/101 completed\n",
      "Train onion_rings 46/101 completed\n",
      "Train red_velvet_cake 47/101 completed\n",
      "Train grilled_salmon 48/101 completed\n",
      "Train chicken_curry 49/101 completed\n",
      "Train deviled_eggs 50/101 completed\n",
      "Train caesar_salad 51/101 completed\n",
      "Train hummus 52/101 completed\n",
      "Train fish_and_chips 53/101 completed\n",
      "Train lasagna 54/101 completed\n",
      "Train peking_duck 55/101 completed\n",
      "Train guacamole 56/101 completed\n",
      "Train strawberry_shortcake 57/101 completed\n",
      "Train clam_chowder 58/101 completed\n",
      "Train croque_madame 59/101 completed\n",
      "Train french_onion_soup 60/101 completed\n",
      "Train beef_carpaccio 61/101 completed\n",
      "Train fried_rice 62/101 completed\n",
      "Train donuts 63/101 completed\n",
      "Train gyoza 64/101 completed\n",
      "Train ravioli 65/101 completed\n",
      "Train fried_calamari 66/101 completed\n",
      "Train spaghetti_carbonara 67/101 completed\n",
      "Train french_toast 68/101 completed\n",
      "Train lobster_bisque 69/101 completed\n",
      "Train ceviche 70/101 completed\n",
      "Train bruschetta 71/101 completed\n",
      "Train french_fries 72/101 completed\n",
      "Train shrimp_and_grits 73/101 completed\n",
      "Train filet_mignon 74/101 completed\n",
      "Train hamburger 75/101 completed\n",
      "Train dumplings 76/101 completed\n",
      "Train tuna_tartare 77/101 completed\n",
      "Train sushi 78/101 completed\n",
      "Train cheese_plate 79/101 completed\n",
      "Train eggs_benedict 80/101 completed\n",
      "Train cup_cakes 81/101 completed\n",
      "Train takoyaki 82/101 completed\n",
      "Train chocolate_mousse 83/101 completed\n",
      "Train breakfast_burrito 84/101 completed\n",
      "Train hot_dog 85/101 completed\n",
      "Train macarons 86/101 completed\n",
      "Train waffles 87/101 completed\n",
      "Train seaweed_salad 88/101 completed\n",
      "Train cannoli 89/101 completed\n",
      "Train huevos_rancheros 90/101 completed\n",
      "Train pizza 91/101 completed\n",
      "Train chicken_quesadilla 92/101 completed\n",
      "Train pho 93/101 completed\n",
      "Train prime_rib 94/101 completed\n",
      "Train cheesecake 95/101 completed\n",
      "Train ice_cream 96/101 completed\n",
      "Train omelette 97/101 completed\n",
      "Train grilled_cheese_sandwich 98/101 completed\n",
      "Train lobster_roll_sandwich 99/101 completed\n",
      "Train nachos 100/101 completed\n",
      "Train oysters 101/101 completed\n",
      "Test churros 1/101 completed\n",
      "Test hot_and_sour_soup 2/101 completed\n",
      "Test samosa 3/101 completed\n",
      "Test sashimi 4/101 completed\n",
      "Test pork_chop 5/101 completed\n",
      "Test spring_rolls 6/101 completed\n",
      "Test panna_cotta 7/101 completed\n",
      "Test beef_tartare 8/101 completed\n",
      "Test greek_salad 9/101 completed\n",
      "Test foie_gras 10/101 completed\n",
      "Test tacos 11/101 completed\n",
      "Test pad_thai 12/101 completed\n",
      "Test poutine 13/101 completed\n",
      "Test ramen 14/101 completed\n",
      "Test pulled_pork_sandwich 15/101 completed\n",
      "Test bibimbap 16/101 completed\n",
      "Test beignets 17/101 completed\n",
      "Test apple_pie 18/101 completed\n",
      "Test crab_cakes 19/101 completed\n",
      "Test risotto 20/101 completed\n",
      "Test paella 21/101 completed\n",
      "Test steak 22/101 completed\n",
      "Test baby_back_ribs 23/101 completed\n",
      "Test miso_soup 24/101 completed\n",
      "Test frozen_yogurt 25/101 completed\n",
      "Test club_sandwich 26/101 completed\n",
      "Test carrot_cake 27/101 completed\n",
      "Test falafel 28/101 completed\n",
      "Test bread_pudding 29/101 completed\n",
      "Test chicken_wings 30/101 completed\n",
      "Test gnocchi 31/101 completed\n",
      "Test caprese_salad 32/101 completed\n",
      "Test creme_brulee 33/101 completed\n",
      "Test escargots 34/101 completed\n",
      "Test chocolate_cake 35/101 completed\n",
      "Test tiramisu 36/101 completed\n",
      "Test spaghetti_bolognese 37/101 completed\n",
      "Test mussels 38/101 completed\n",
      "Test scallops 39/101 completed\n",
      "Test baklava 40/101 completed\n",
      "Test edamame 41/101 completed\n",
      "Test macaroni_and_cheese 42/101 completed\n",
      "Test pancakes 43/101 completed\n",
      "Test garlic_bread 44/101 completed\n",
      "Test beet_salad 45/101 completed\n",
      "Test onion_rings 46/101 completed\n",
      "Test red_velvet_cake 47/101 completed\n",
      "Test grilled_salmon 48/101 completed\n",
      "Test chicken_curry 49/101 completed\n",
      "Test deviled_eggs 50/101 completed\n",
      "Test caesar_salad 51/101 completed\n",
      "Test hummus 52/101 completed\n",
      "Test fish_and_chips 53/101 completed\n",
      "Test lasagna 54/101 completed\n",
      "Test peking_duck 55/101 completed\n",
      "Test guacamole 56/101 completed\n",
      "Test strawberry_shortcake 57/101 completed\n",
      "Test clam_chowder 58/101 completed\n",
      "Test croque_madame 59/101 completed\n",
      "Test french_onion_soup 60/101 completed\n",
      "Test beef_carpaccio 61/101 completed\n",
      "Test fried_rice 62/101 completed\n",
      "Test donuts 63/101 completed\n",
      "Test gyoza 64/101 completed\n",
      "Test ravioli 65/101 completed\n",
      "Test fried_calamari 66/101 completed\n",
      "Test spaghetti_carbonara 67/101 completed\n",
      "Test french_toast 68/101 completed\n",
      "Test lobster_bisque 69/101 completed\n",
      "Test ceviche 70/101 completed\n",
      "Test bruschetta 71/101 completed\n",
      "Test french_fries 72/101 completed\n",
      "Test shrimp_and_grits 73/101 completed\n",
      "Test filet_mignon 74/101 completed\n",
      "Test hamburger 75/101 completed\n",
      "Test dumplings 76/101 completed\n",
      "Test tuna_tartare 77/101 completed\n",
      "Test sushi 78/101 completed\n",
      "Test cheese_plate 79/101 completed\n",
      "Test eggs_benedict 80/101 completed\n",
      "Test cup_cakes 81/101 completed\n",
      "Test takoyaki 82/101 completed\n",
      "Test chocolate_mousse 83/101 completed\n",
      "Test breakfast_burrito 84/101 completed\n",
      "Test hot_dog 85/101 completed\n",
      "Test macarons 86/101 completed\n",
      "Test waffles 87/101 completed\n",
      "Test seaweed_salad 88/101 completed\n",
      "Test cannoli 89/101 completed\n",
      "Test huevos_rancheros 90/101 completed\n",
      "Test pizza 91/101 completed\n",
      "Test chicken_quesadilla 92/101 completed\n",
      "Test pho 93/101 completed\n",
      "Test prime_rib 94/101 completed\n",
      "Test cheesecake 95/101 completed\n",
      "Test ice_cream 96/101 completed\n",
      "Test omelette 97/101 completed\n",
      "Test grilled_cheese_sandwich 98/101 completed\n",
      "Test lobster_roll_sandwich 99/101 completed\n",
      "Test nachos 100/101 completed\n",
      "Test oysters 101/101 completed\n"
     ]
    }
   ],
   "source": [
    "# given_root = 'food-101/images'\n",
    "\n",
    "shutil.rmtree('Food_data', ignore_errors=True)\n",
    "\n",
    "os.mkdir('Food_data')\n",
    "train_root = os.path.join('Food_data', 'train')\n",
    "os.mkdir(train_root)\n",
    "\n",
    "with open('data/food/meta/train.json') as f:\n",
    "    train_json = json.load(f)\n",
    "\n",
    "for i, item in enumerate(train_json.items()):\n",
    "    des = os.path.join(train_root, item[0])\n",
    "    os.mkdir(des)\n",
    "\n",
    "    for v in item[1]:\n",
    "        src = os.path.join(given_root, v)\n",
    "        shutil.copy2(src + '.jpg', des)\n",
    "\n",
    "    print('Train {} {}/{} completed'.format(item[0], i+1, len(train_json)))\n",
    "\n",
    "test_root = os.path.join('Food_data', 'test')\n",
    "os.mkdir(test_root)\n",
    "\n",
    "with open('data/food/meta/test.json') as f:\n",
    "    test_json = json.load(f)\n",
    "\n",
    "for i, item in enumerate(test_json.items()):\n",
    "    des = os.path.join(test_root, item[0])\n",
    "    os.mkdir(des)\n",
    "\n",
    "    for v in item[1]:\n",
    "        src = os.path.join(given_root, v)\n",
    "        shutil.copy2(src + '.jpg', des)\n",
    "\n",
    "    print('Test {} {}/{} completed'.format(item[0], i+1, len(test_json)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RVstWzMi8JsW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75750\n",
      "25250\n"
     ]
    }
   ],
   "source": [
    "print(len(list(iglob(\"Food_data/train/*/*.jpg\", recursive=True))))\n",
    "print(len(list(iglob(\"Food_data/test/*/*.jpg\", recursive=True))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K75QsT79kpaD"
   },
   "source": [
    "# Pre-process Images\n",
    "## Objectives\n",
    "1. Implement preprocessing codes for each model. \n",
    "2. Augment the dataset. \n",
    "3. Preview the preprocessed dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pILxzRqEljEa"
   },
   "source": [
    "### Preprocessing steps for Medium model (Pytorch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zmK0PrInnroT"
   },
   "outputs": [],
   "source": [
    "# config\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "\n",
    "        self._configs = {}\n",
    "        self._configs[\"device\"] = torch.device('cpu')\n",
    "        self._configs[\"seed\"] = 11\n",
    "\n",
    "        self._configs[\"randaug\"] = (2, 10)\n",
    "        self._configs[\"resize\"] = 128\n",
    "        self._configs[\"batch\"] = 16\n",
    "        self._configs[\"drop_last\"] = True\n",
    "\n",
    "        # model config\n",
    "        self._configs[\"num_classes\"] = 101\n",
    "        self._configs[\"depth\"] = 28\n",
    "        self._configs[\"widen_factor\"] = 8\n",
    "        self._configs[\"dense_dropout\"] = 0.1\n",
    "\n",
    "        # training config\n",
    "        self._configs[\"name\"] = 'exp_1'\n",
    "        self._configs[\"save_path\"] = '/content/drive/MyDrive/food_weights/WideResNet'\n",
    "        self._configs[\"lr\"] = 0.01\n",
    "        self._configs[\"momentum\"] = 0.9\n",
    "        self._configs[\"weight_decay\"] = 5e-4\n",
    "\n",
    "        self._configs[\"label_smoothing\"] = 0.15\n",
    "        self._configs[\"epochs\"] = 30\n",
    "        self._configs[\"start_epoch\"] = 0\n",
    "        self._configs[\"amp\"] = False\n",
    "        self._configs[\"best_top1\"] = 0.0\n",
    "        self._configs[\"best_top5\"] = 0.0\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self._configs[\"device\"]\n",
    "\n",
    "    @property\n",
    "    def seed(self):\n",
    "        return self._configs[\"seed\"]\n",
    "\n",
    "    @property\n",
    "    def randaug(self):\n",
    "        return self._configs[\"randaug\"]\n",
    "\n",
    "    @property\n",
    "    def resize(self):\n",
    "        return self._configs[\"resize\"]\n",
    "\n",
    "    @property\n",
    "    def batch(self):\n",
    "        return self._configs[\"batch\"]\n",
    "\n",
    "    @property\n",
    "    def drop_last(self):\n",
    "        return self._configs[\"drop_last\"]\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self._configs[\"num_classes\"]\n",
    "\n",
    "    @property\n",
    "    def depth(self):\n",
    "        return self._configs[\"depth\"]\n",
    "\n",
    "    @property\n",
    "    def widen_factor(self):\n",
    "        return self._configs[\"widen_factor\"]\n",
    "\n",
    "    @property\n",
    "    def dense_dropout(self):\n",
    "        return self._configs[\"dense_dropout\"]\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._configs[\"name\"]\n",
    "\n",
    "    @property\n",
    "    def save_path(self):\n",
    "        return self._configs[\"save_path\"]\n",
    "\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self._configs[\"lr\"]\n",
    "\n",
    "    @property\n",
    "    def momentum(self):\n",
    "        return self._configs[\"momentum\"]\n",
    "\n",
    "    @property\n",
    "    def weight_decay(self):\n",
    "        return self._configs[\"weight_decay\"]\n",
    "\n",
    "    @property\n",
    "    def label_smoothing(self):\n",
    "        return self._configs[\"label_smoothing\"]\n",
    "\n",
    "    @property\n",
    "    def epochs(self):\n",
    "        return self._configs[\"epochs\"]\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def start_epoch(self):\n",
    "        return self._configs[\"start_epoch\"]\n",
    "\n",
    "    @property\n",
    "    def amp(self):\n",
    "        return self._configs[\"amp\"]\n",
    "\n",
    "    def best_top1(self, item=None):\n",
    "        if item == None:\n",
    "            return self._configs[\"best_top1\"]\n",
    "        self._configs[\"best_top1\"] = item   \n",
    "\n",
    "    def best_top5(self, item=None):\n",
    "        if item == None:\n",
    "            return self._configs[\"best_top5\"]\n",
    "        self._configs[\"best_top5\"] = item            \n",
    "\n",
    "    def change_optim(self, lr, m, w):\n",
    "        self._configs[\"lr\"] = lr\n",
    "        self._configs[\"momentum\"] = m\n",
    "        self._configs[\"weight_decay\"] = w\n",
    "\n",
    "    def set_start_epoch(self, epoch):\n",
    "        self._configs[\"start_epoch\"] = epoch\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YMxJ_tv5K9hj"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "PARAMETER_MAX = 10\n",
    "RESAMPLE_MODE = None\n",
    "\n",
    "\n",
    "def AutoContrast(img, **kwarg):\n",
    "    return PIL.ImageOps.autocontrast(img)\n",
    "\n",
    "\n",
    "def Brightness(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
    "\n",
    "\n",
    "def Color(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
    "\n",
    "\n",
    "def Contrast(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
    "\n",
    "\n",
    "def Cutout(img, v, max_v, **kwarg):\n",
    "    if v == 0:\n",
    "        return img\n",
    "    v = _float_parameter(v, max_v)\n",
    "    v = int(v * min(img.size))\n",
    "    w, h = img.size\n",
    "    x0 = np.random.uniform(0, w)\n",
    "    y0 = np.random.uniform(0, h)\n",
    "    x0 = int(max(0, x0 - v / 2.))\n",
    "    y0 = int(max(0, y0 - v / 2.))\n",
    "    x1 = int(min(w, x0 + v))\n",
    "    y1 = int(min(h, y0 + v))\n",
    "    xy = (x0, y0, x1, y1)\n",
    "    # gray\n",
    "    color = (127, 127, 127)\n",
    "    img = img.copy()\n",
    "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
    "    return img\n",
    "\n",
    "\n",
    "def CutoutConst(img, v, max_v, **kwarg):\n",
    "    v = _int_parameter(v, max_v)\n",
    "    w, h = img.size\n",
    "    x0 = np.random.uniform(0, w)\n",
    "    y0 = np.random.uniform(0, h)\n",
    "    x0 = int(max(0, x0 - v / 2.))\n",
    "    y0 = int(max(0, y0 - v / 2.))\n",
    "    x1 = int(min(w, x0 + v))\n",
    "    y1 = int(min(h, y0 + v))\n",
    "    xy = (x0, y0, x1, y1)\n",
    "    # gray\n",
    "    color = (127, 127, 127)\n",
    "    img = img.copy()\n",
    "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
    "    return img\n",
    "\n",
    "\n",
    "def Equalize(img, **kwarg):\n",
    "    return PIL.ImageOps.equalize(img)\n",
    "\n",
    "\n",
    "def Identity(img, **kwarg):\n",
    "    return img\n",
    "\n",
    "\n",
    "def Invert(img, **kwarg):\n",
    "    return PIL.ImageOps.invert(img)\n",
    "\n",
    "\n",
    "def Posterize(img, v, max_v, bias, **kwarg):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    return PIL.ImageOps.posterize(img, v)\n",
    "\n",
    "\n",
    "def Rotate(img, v, max_v, **kwarg):\n",
    "    v = _float_parameter(v, max_v)\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.rotate(v)\n",
    "\n",
    "\n",
    "def Sharpness(img, v, max_v, bias):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
    "\n",
    "\n",
    "def ShearX(img, v, max_v, **kwarg):\n",
    "    v = _float_parameter(v, max_v)\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0), RESAMPLE_MODE)\n",
    "\n",
    "\n",
    "def ShearY(img, v, max_v, **kwarg):\n",
    "    v = _float_parameter(v, max_v)\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0), RESAMPLE_MODE)\n",
    "\n",
    "\n",
    "def Solarize(img, v, max_v, **kwarg):\n",
    "    v = _int_parameter(v, max_v)\n",
    "    return PIL.ImageOps.solarize(img, 256 - v)\n",
    "\n",
    "\n",
    "def SolarizeAdd(img, v, max_v, threshold=128, **kwarg):\n",
    "    v = _int_parameter(v, max_v)\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    img_np = np.array(img).astype(np.int)\n",
    "    img_np = img_np + v\n",
    "    img_np = np.clip(img_np, 0, 255)\n",
    "    img_np = img_np.astype(np.uint8)\n",
    "    img = Image.fromarray(img_np)\n",
    "    return PIL.ImageOps.solarize(img, threshold)\n",
    "\n",
    "\n",
    "def TranslateX(img, v, max_v, **kwarg):\n",
    "    v = _float_parameter(v, max_v)\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    v = int(v * img.size[0])\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0), RESAMPLE_MODE)\n",
    "\n",
    "\n",
    "def TranslateY(img, v, max_v, **kwarg):\n",
    "    v = _float_parameter(v, max_v)\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    v = int(v * img.size[1])\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v), RESAMPLE_MODE)\n",
    "\n",
    "\n",
    "def TranslateXConst(img, v, max_v, **kwarg):\n",
    "    v = _float_parameter(v, max_v)\n",
    "    if random.random() > 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0), RESAMPLE_MODE)\n",
    "\n",
    "\n",
    "def TranslateYConst(img, v, max_v, **kwarg):\n",
    "    v = _float_parameter(v, max_v)\n",
    "    if random.random() > 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v), RESAMPLE_MODE)\n",
    "\n",
    "\n",
    "def _float_parameter(v, max_v):\n",
    "    return float(v) * max_v / PARAMETER_MAX\n",
    "\n",
    "\n",
    "def _int_parameter(v, max_v):\n",
    "    return int(v * max_v / PARAMETER_MAX)\n",
    "\n",
    "\n",
    "def rand_augment_pool():\n",
    "    augs = [(AutoContrast, None, None),\n",
    "            (Brightness, 1.8, 0.1),\n",
    "            (Color, 1.8, 0.1),\n",
    "            (Contrast, 1.8, 0.1),\n",
    "            (CutoutConst, 40, None),\n",
    "            (Equalize, None, None),\n",
    "            (Invert, None, None),\n",
    "            (Posterize, 4, 0),\n",
    "            (Rotate, 30, None),\n",
    "            (Sharpness, 1.8, 0.1),\n",
    "            (ShearX, 0.3, None),\n",
    "            (ShearY, 0.3, None),\n",
    "            (Solarize, 256, None),\n",
    "            (TranslateXConst, 100, None),\n",
    "            (TranslateYConst, 100, None),\n",
    "            ]\n",
    "    return augs\n",
    "\n",
    "\n",
    "class RandAugment(object):\n",
    "    def __init__(self, n, m, resample_mode=PIL.Image.BILINEAR):\n",
    "        assert n >= 1\n",
    "        assert m >= 1\n",
    "        global RESAMPLE_MODE\n",
    "        RESAMPLE_MODE = resample_mode\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.augment_pool = rand_augment_pool()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        ops = random.choices(self.augment_pool, k=self.n)\n",
    "        for op, max_v, bias in ops:\n",
    "            prob = np.random.uniform(0.2, 0.8)\n",
    "            if random.random() + prob >= 1:\n",
    "                img = op(img, v=self.m, max_v=max_v, bias=bias)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "USrwfYGyOf2n"
   },
   "outputs": [],
   "source": [
    "# define Random Transforms class\n",
    "\n",
    "class TransformMPL(object):\n",
    "    def __init__(self, config, mean, std):\n",
    "        if config.randaug:\n",
    "            n, m = config.randaug\n",
    "        else:\n",
    "            n, m = 2, 10  # default\n",
    "\n",
    "        self.aug = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(size=config.resize,\n",
    "                                  padding=int(config.resize*0.125),\n",
    "                                  padding_mode='reflect'),\n",
    "            RandAugment(n=n, m=m)])\n",
    "        self.normalize = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        aug = self.aug(x)\n",
    "        return self.normalize(aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "333_9LMGboFP"
   },
   "outputs": [],
   "source": [
    "# Image Net mean and std\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_set = datasets.ImageFolder('Food_data/train',\n",
    "                                 transform=TransformMPL(config, mean=mean, std=std),\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_set,\n",
    "                          sampler=RandomSampler(train_set),\n",
    "                          batch_size=config.batch,\n",
    "                          drop_last=config.drop_last,\n",
    "                          pin_memory=True)\n",
    "\n",
    "test_set = datasets.ImageFolder('Food_data/test',\n",
    "                                 transform=TransformMPL(config, mean=mean, std=std),\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_set,\n",
    "                         batch_size=config.batch,\n",
    "                         sampler=SequentialSampler(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lykMyaCui3ZF"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51628/24510180.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'   '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%5s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "def imshow(img):\n",
    "    img = inv_normalize(img)     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "def inv_normalize(img):\n",
    "    mean = torch.Tensor([0.485, 0.456, 0.406]).unsqueeze(-1)\n",
    "    std= torch.Tensor([0.229, 0.224, 0.225]).unsqueeze(-1)\n",
    "    img = (img.view(3, -1) * std + mean).view(img.shape)\n",
    "    img = img.clamp(0, 1)\n",
    "    return img\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('   '.join('%5s' % train_set.classes[labels[j]] for j in range(config.batch)))\n",
    "\n",
    "images, labels = next(iter(test_loader))\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('   '.join('%5s' % test_set.classes[labels[j]] for j in range(config.batch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlzbiAGXmKJJ"
   },
   "source": [
    "### Preprocessing steps for light model (TF EfficientNetB0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeRAeWoKmgts"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "images = []\n",
    "labels  = []\n",
    "TRAIN_DIR = 'Food_data/train'\n",
    "VAL_DIR = 'Food_data/test'\n",
    "IMG_SIZE = (224,224) # Image resolution\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    image_size=(224, 224),\n",
    "    batch_size= BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    label_mode = 'categorical',\n",
    ")\n",
    "\n",
    "valid_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    image_size=(224, 224),\n",
    "    batch_size= BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    seed = 123,\n",
    "    label_mode = 'categorical',\n",
    ")\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpWOls_ZqhgF"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_data.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in valid_data.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDuMB5EzrX8A"
   },
   "source": [
    "### Preprocessing steps for heavier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0eHKYgc8rZlw"
   },
   "outputs": [],
   "source": [
    "# preprocessing step for pytorch models are same and preprocessing \n",
    "# steps for tf models are same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmylPbYmsB92"
   },
   "source": [
    "# Training different models\n",
    "## Objectives\n",
    "1. Obtain 90% accuracy in all the models trained. \n",
    "2. You're free to use any techniques for traning such as transfer learning, knowledge transfer, etc. \n",
    "3. The models should not overfit the training dataset. \n",
    "4. Measure the performance in terms of accuracy and speed of each model. \n",
    "5. Visualize the training and testing performance using TensorBoard. \n",
    "\n",
    "#### Optional:\n",
    "1. Apply weight quantization to increase the speed of the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFGzTa4DsPat"
   },
   "source": [
    "## Train wideResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-S_fMrJGIx73"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ModelEMA(nn.Module):\n",
    "    def __init__(self, model, decay=0.9999, device=None):\n",
    "        super().__init__()\n",
    "        self.module = deepcopy(model)\n",
    "        self.module.eval()\n",
    "        self.decay = decay\n",
    "        self.device = device\n",
    "        if self.device is not None:\n",
    "            self.module.to(device=device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.module(input)\n",
    "\n",
    "    def _update(self, model, update_fn):\n",
    "        with torch.no_grad():\n",
    "            for ema_v, model_v in zip(self.module.parameters(), model.parameters()):\n",
    "                if self.device is not None:\n",
    "                    model_v = model_v.to(device=self.device)\n",
    "                ema_v.copy_(update_fn(ema_v, model_v))\n",
    "            for ema_v, model_v in zip(self.module.buffers(), model.buffers()):\n",
    "                if self.device is not None:\n",
    "                    model_v = model_v.to(device=self.device)\n",
    "                ema_v.copy_(model_v)\n",
    "\n",
    "    def update_parameters(self, model):\n",
    "        self._update(model, update_fn=lambda e, m: self.decay * e + (1. - self.decay) * m)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.module.state_dict()\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.module.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VM4lPumUI5Da"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, dropout=0.0, activate_before_residual=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes, momentum=0.001)\n",
    "        self.relu1 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes, momentum=0.001)\n",
    "        self.relu2 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.dropout = dropout\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes,\n",
    "                                                                kernel_size=1, stride=stride,\n",
    "                                                                padding=0, bias=False) or None\n",
    "        self.activate_before_residual = activate_before_residual\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut and self.activate_before_residual == True:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.dropout > 0:\n",
    "            out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5XhMkRnI-E7"
   },
   "outputs": [],
   "source": [
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropout=0.0,\n",
    "                 activate_before_residual=False):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(\n",
    "            block, in_planes, out_planes, nb_layers, stride, dropout, activate_before_residual)\n",
    "\n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropout,\n",
    "                    activate_before_residual):\n",
    "        layers = []\n",
    "        for i in range(int(nb_layers)):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes,\n",
    "                                i == 0 and stride or 1, dropout, activate_before_residual))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EF8ZzuySJAJ1"
   },
   "outputs": [],
   "source": [
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, num_classes, depth=28, widen_factor=2, dropout=0.0, dense_dropout=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        channels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) / 6\n",
    "        block = BasicBlock\n",
    "        # 1st conv before any network block\n",
    "        self.conv1 = nn.Conv2d(3, channels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(\n",
    "            n, channels[0], channels[1], block, 1, dropout, activate_before_residual=True)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(\n",
    "            n, channels[1], channels[2], block, 2, dropout)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(\n",
    "            n, channels[2], channels[3], block, 2, dropout)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(channels[3], momentum=0.001)\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.drop = nn.Dropout(dense_dropout)\n",
    "        self.fc = nn.Linear(channels[3], num_classes)\n",
    "        self.channels = channels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,\n",
    "                                        mode='fan_out',\n",
    "                                        nonlinearity='leaky_relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = F.adaptive_avg_pool2d(out, 1)\n",
    "        out = out.view(-1, self.channels)\n",
    "        return self.fc(self.drop(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KW2TE0jWJC8x"
   },
   "outputs": [],
   "source": [
    "def build_wideresnet(config):\n",
    "\n",
    "    model = WideResNet(num_classes=config.num_classes,\n",
    "                       depth=config.depth,\n",
    "                       widen_factor=config.widen_factor,\n",
    "                       dropout=0,\n",
    "                       dense_dropout=config.dense_dropout)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yg0a6jOeqtZt"
   },
   "outputs": [],
   "source": [
    "model = build_wideresnet(config)\n",
    "model_params = sum(p.numel() for p in model.parameters())\n",
    "print('Total parameters {} M'.format(model_params/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_Cq6a0yJsom"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import distributed as dist\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJiMVTrfJ8PR"
   },
   "outputs": [],
   "source": [
    "def reduce_tensor(tensor, n):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.ReduceOp.SUM)\n",
    "    rt /= n\n",
    "    return rt\n",
    "\n",
    "\n",
    "def create_loss_fn(config):\n",
    "    if config.label_smoothing > 0:\n",
    "        criterion = SmoothCrossEntropy(alpha=config.label_smoothing)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    return criterion.to(config.device)\n",
    "\n",
    "\n",
    "def module_load_state_dict(model, state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:]  # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "\n",
    "def model_load_state_dict(model, state_dict):\n",
    "    try:\n",
    "        model.load_state_dict(state_dict)\n",
    "    except:\n",
    "        module_load_state_dict(model, state_dict)\n",
    "\n",
    "\n",
    "def save_checkpoint(config, state, is_best):\n",
    "    os.makedirs(config.save_path, exist_ok=True)\n",
    "    \n",
    "    name = config.name\n",
    "    filename = f'{config.save_path}/{name}_last.pth.tar'\n",
    "    torch.save(state, filename, _use_new_zipfile_serialization=False)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, f'{config.save_path}/{config.name}_best.pth.tar')\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    output = output.to(torch.device('cpu'))\n",
    "    target = target.to(torch.device('cpu'))\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.shape[0]\n",
    "\n",
    "    _, idx = output.sort(dim=1, descending=True)\n",
    "    pred = idx.narrow(1, 0, maxk).t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(dim=0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qtGaS0dKAWM"
   },
   "outputs": [],
   "source": [
    "class SmoothCrossEntropy(nn.Module):\n",
    "    def __init__(self, alpha=0.1):\n",
    "        super(SmoothCrossEntropy, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        num_classes = logits.shape[-1]\n",
    "        alpha_div_k = self.alpha / num_classes\n",
    "        target_probs = F.one_hot(labels, num_classes=num_classes).float() * \\\n",
    "            (1. - self.alpha) + alpha_div_k\n",
    "        loss = -(target_probs * torch.log_softmax(logits, dim=-1)).sum(dim=-1)\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyqfypouMloa"
   },
   "outputs": [],
   "source": [
    "def set_seed(config):\n",
    "    random.seed(config.seed)\n",
    "    np.random.seed(config.seed)\n",
    "    torch.manual_seed(config.seed)\n",
    "    torch.cuda.manual_seed_all(config.seed)\n",
    "\n",
    "def get_cosine_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps,\n",
    "                                    num_training_steps,\n",
    "                                    num_cycles=0.5,\n",
    "                                    last_epoch=-1):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "\n",
    "        progress = float(current_step - num_warmup_steps) / \\\n",
    "            float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n",
    "\n",
    "    return LambdaLR(optimizer, lr_lambda, last_epoch)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    return optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyz2jcaMM1VF"
   },
   "outputs": [],
   "source": [
    "def train(config, train_loader, test_loader,\n",
    "          model, criterion, optimizer, scaler):\n",
    "\n",
    "    for epoch in range(config.start_epoch, config.epochs):\n",
    "\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "\n",
    "        model.train()\n",
    "        end = time.time()\n",
    "\n",
    "        for step, (images, targets) in enumerate(train_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            batch_size = targets.shape[0]\n",
    "            images = images.to(config.device)\n",
    "            targets = targets.to(config.device)\n",
    "            with amp.autocast(enabled=config.amp):\n",
    "                model.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            batch_time.update(time.time() - end)\n",
    "\n",
    "        message = 'Epoch : {0}/{1} Data : {2:.2f} Batch : {3:.2f} Loss : {4:.4f}'.format(\n",
    "            epoch+1, config.epochs, data_time.avg, batch_time.avg, losses.avg\n",
    "        )\n",
    "\n",
    "        print(message)\n",
    "\n",
    "        test_loss, top1, top5 = evaluate(config, test_loader, model, criterion)\n",
    "        is_best = top1 > config.best_top1()\n",
    "\n",
    "        if is_best:\n",
    "            config.best_top1(top1)\n",
    "            config.best_top5(top5)\n",
    "\n",
    "        save_checkpoint(config, {\n",
    "            'step': step + 1,\n",
    "            'best_top1': config.best_top1(),\n",
    "            'best_top5': config.best_top5(),\n",
    "            'student_state_dict': model.state_dict(),\n",
    "            'avg_state_dict': None,\n",
    "            'student_optimizer': optimizer.state_dict(),\n",
    "        }, is_best)\n",
    "\n",
    "def evaluate(config, test_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for step, (images, targets) in enumerate(test_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "            batch_size = targets.shape[0]\n",
    "            images = images.to(config.device)\n",
    "            targets = targets.to(config.device)\n",
    "            with amp.autocast(enabled=config.amp):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            acc1, acc5 = accuracy(outputs, targets, (1, 5))\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            top1.update(acc1[0], batch_size)\n",
    "            top5.update(acc5[0], batch_size)\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "        message = 'Data : {0:.2f} Batch : {1:.2f} Loss : {2:.4f} top1 : {3:.2f} top5 : {4:.2f}'.format(\n",
    "            data_time.avg, batch_time.avg,\n",
    "            losses.avg, top1.avg, top5.avg,\n",
    "        )\n",
    "\n",
    "        print(message)\n",
    "\n",
    "        return losses.avg, top1.avg, top5.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swtIJjq1b0Nq"
   },
   "outputs": [],
   "source": [
    "set_seed(config)\n",
    "\n",
    "model = build_wideresnet(config)\n",
    "model.to(config.device)\n",
    "\n",
    "state_dict = torch.load(config.save_path + '/' + config.name + '_best.pth.tar',\n",
    "                        map_location=torch.device('cpu'))\n",
    "\n",
    "model.load_state_dict(state_dict[\"student_state_dict\"])\n",
    "config.best_top1(state_dict[\"best_top1\"])\n",
    "config.best_top5(state_dict[\"best_top5\"])\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=config.lr,\n",
    "                      momentum=config.momentum,\n",
    "                      weight_decay=config.weight_decay)\n",
    "\n",
    "optimizer.load_state_dict(state_dict[\"student_optimizer\"])\n",
    "config.change_optim(lr=optimizer.param_groups[0]['lr'],\n",
    "                    m=optimizer.param_groups[0]['momentum'],\n",
    "                    w=optimizer.param_groups[0]['weight_decay'])\n",
    "\n",
    "config.set_start_epoch(4)\n",
    "\n",
    "criterion = create_loss_fn(config)\n",
    "\n",
    "scaler = amp.GradScaler(enabled=config.amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iQA3jarQzRz"
   },
   "outputs": [],
   "source": [
    "optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvJM5mbgdyki"
   },
   "outputs": [],
   "source": [
    "train(config, train_loader, test_loader,\n",
    "          model, criterion, optimizer, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmwfhTApsVj9"
   },
   "source": [
    "## Train EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7zq7K1msa6X"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import *\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  Resizing(224, 224),\n",
    "  Rescaling(1 /255)\n",
    "])\n",
    "\n",
    "# Data augmentation to reduce overtraining\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "     RandomFlip(\"horizontal\", \n",
    "     input_shape=(224, 224,3)),\n",
    "     RandomRotation(0.1),\n",
    "     RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        #resize_and_rescale,\n",
    "        data_augmentation,\n",
    "        tf.keras.applications.EfficientNetB0(\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            drop_connect_rate=0.5\n",
    "        ),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(101, activation='softmax') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4R0Ec4Esef6"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "history = model.fit(\n",
    "    train_data, \n",
    "    validation_data=valid_data,\n",
    "    epochs= 30,\n",
    ")\n",
    "\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"tf_efficientNetB0_ft.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "model.save_weights(\"tf_efficientNetB0_ft.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ovfJ2ZLsqDl"
   },
   "source": [
    "## Train Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1kmcX4JswPO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "\n",
    "from timm.models.vision_transformer import VisionTransformer, _cfg\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.layers import trunc_normal_\n",
    "\n",
    "\n",
    "class DistilledVisionTransformer(VisionTransformer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dist_token = nn.Parameter(torch.zeros(1, 1, self.embed_dim))\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 2, self.embed_dim))\n",
    "        self.head_dist = nn.Linear(self.embed_dim, self.num_classes) if self.num_classes > 0 else nn.Identity()\n",
    "\n",
    "        trunc_normal_(self.dist_token, std=.02)\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "        self.head_dist.apply(self._init_weights)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        dist_token = self.dist_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        return x[:, 0], x[:, 1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, x_dist = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        x_dist = self.head_dist(x_dist)\n",
    "        if self.training:\n",
    "            return x, x_dist\n",
    "        else:\n",
    "            # during inference, return the average of both classifier predictions\n",
    "            return (x + x_dist) / 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcmPzJeCs95o"
   },
   "outputs": [],
   "source": [
    "from timm.data import Mixup\n",
    "from timm.models import create_model\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.optim import create_optimizer\n",
    "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
    "\n",
    "model = create_model(\n",
    "    'deit_base_patch16_224',\n",
    "    pretrained=False,\n",
    "    num_classes=101,\n",
    "    drop_rate=0.0,\n",
    "    drop_path_rate=0.1,\n",
    "    drop_block_rate=None,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = LabelSmoothingCrossEntropy()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, betas=[0.9, 0.999])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRreXg4rtKvW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def train(n_epochs,trainloader,testloader, model, optimizer, criterion):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    running_loss=0\n",
    "    \n",
    "  \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        for inputs, labels in tqdm(trainloader):\n",
    "            \n",
    "        # Move input and label tensors to the default device\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            start = time.time()\n",
    "            logps = model(inputs)\n",
    "            loss = criterion(logps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        valid_loss=0\n",
    "        accuracy=0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(testloader):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                logps = model(inputs)\n",
    "                batch_loss = criterion(logps, labels)\n",
    "                valid_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                \n",
    "                top_p, top_class = logps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "           \n",
    "        \n",
    "            if valid_loss <= valid_loss_min:\n",
    "                print(\"Validation loss decreased  Saving model\")\n",
    "                torch.save(model.state_dict(),'food_classifier_deit.pt')\n",
    "                valid_loss_min=valid_loss\n",
    "                \n",
    "            \n",
    "            print(f\"Device = cuda; Time per batch: {(time.time() - start):.3f} seconds\")       \n",
    "            print(f\"Epoch {epoch}/{n_epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/len(trainloader):.3f}.. \"\n",
    "                  f\"Test loss: {valid_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mC6btMH2tLqc"
   },
   "outputs": [],
   "source": [
    "train(30, train_loader, test_loader, model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpO6P7pataZB"
   },
   "source": [
    "## Train DanseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywd71Wb3telS"
   },
   "outputs": [],
   "source": [
    "model_ft = torchvision.models.densenet201(pretrained=True)\n",
    "model_ft.classifier = nn.Sequential(nn.Linear(1920,1024),nn.LeakyReLU(),nn.Linear(1024,101))\n",
    "\n",
    "# Use GPU if it's available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=0.001, betas=[0.9, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUyOUH0FtjT2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def train(n_epochs,trainloader,testloader, model, optimizer, criterion):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    running_loss=0\n",
    "    \n",
    "  \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        for inputs, labels in tqdm(trainloader):\n",
    "            \n",
    "        # Move input and label tensors to the default device\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            start = time.time()\n",
    "            logps = model(inputs)\n",
    "            loss = criterion(logps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        valid_loss=0\n",
    "        accuracy=0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(testloader):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                logps = model(inputs)\n",
    "                batch_loss = criterion(logps, labels)\n",
    "                valid_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                \n",
    "                top_p, top_class = logps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "           \n",
    "        \n",
    "            if valid_loss <= valid_loss_min:\n",
    "                print(\"Validation loss decreased  Saving model\")\n",
    "                torch.save(model.state_dict(),'food_classifier_deit.pt')\n",
    "                valid_loss_min=valid_loss\n",
    "                \n",
    "            \n",
    "            print(f\"Device = cuda; Time per batch: {(time.time() - start):.3f} seconds\")       \n",
    "            print(f\"Epoch {epoch}/{n_epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/len(trainloader):.3f}.. \"\n",
    "                  f\"Test loss: {valid_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asHqQjJMtliK"
   },
   "outputs": [],
   "source": [
    "train(30, train_dl, val_dl, model_ft, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YG1tbO76tzih"
   },
   "source": [
    "## Train MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKgzwJIct9Ga"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "model_ft = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "set_parameter_requires_grad(model_ft, True)\n",
    "num_ftrs = model_ft.classifier[1].in_features\n",
    "model_ft.classifier[1] = nn.Linear(num_ftrs,101)\n",
    "\n",
    "def train(start_epoch, best_acc_, model, train_dl, val_dl, criterion, optimizer, num_epochs=25):\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = best_acc_\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        model.train()\n",
    "        for i,batch in enumerate(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch[0].cuda())\n",
    "            loss = criterion(outputs, batch[1].cuda())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * batch[0].size(0)\n",
    "            running_corrects += torch.sum(preds == batch[1].cuda().data)\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                print('{}/{}'.format(i, len(train_dl)))\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dl.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dl.dataset)\n",
    "\n",
    "        print('Epoch {} Training Loss: {:.4f} Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            model.eval()\n",
    "            for i,batch in enumerate(val_dl):\n",
    "\n",
    "                outputs = model(batch[0].cuda())\n",
    "                loss = criterion(outputs, batch[1].cuda())\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                running_loss += loss.item() * batch[0].size(0)\n",
    "                running_corrects += torch.sum(preds == batch[1].cuda().data)\n",
    "\n",
    "            epoch_loss = running_loss / len(val_dl.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(val_dl.dataset)\n",
    "\n",
    "            print('Evaluation Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "            ckpt = {\n",
    "                \"model_dict\": model.state_dict(),\n",
    "                \"best_acc\": epoch_acc,\n",
    "                \"optim_dict\": optimizer.state_dict(),\n",
    "                \"epoch\": epoch,\n",
    "            }\n",
    "            save_path = '/content/drive/MyDrive/food_weights/WideResNetV2/epoch_{}.pt'.format(epoch+1)\n",
    "            torch.save(ckpt, save_path)\n",
    "\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            val_acc_history.append(epoch_acc)\n",
    "\n",
    "    return best_model_wts, val_acc_history, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jq3SJqVhuG5a"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "feature_extract = True\n",
    "\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YsuNHvx8uJmI"
   },
   "outputs": [],
   "source": [
    "ckpt_ = '/content/drive/MyDrive/food_weights/MobileNet/epoch_9.pt'\n",
    "ckpt = torch.load(ckpt_)\n",
    "model_ft.load_state_dict(ckpt[\"model_dict\"])\n",
    "optimizer_ft.load_state_dict(ckpt[\"optim_dict\"])\n",
    "start_epoch = ckpt[\"epoch\"] + 1\n",
    "best_acc = ckpt[\"best_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TfOheefFuQi2"
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "model_ft, hist, best_acc = train(0, 0, model_ft, train_dl, val_dl, criterion, optimizer_ft, num_epochs=30)\n",
    "time_elapsed = time.time() - t\n",
    "print('\\n\\n')\n",
    "print(time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXOxPhozuWen"
   },
   "source": [
    "# Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qf1xzaURPLeA"
   },
   "source": [
    "Model | top1 accuracy | top5 accuracy | model parameters (M)\n",
    "-------|---------------|------------- | ------------\n",
    "WRS    | 88.72          | 97.92 | 23.40\n",
    "DenseNet201 | 78.26      | 86.42 | 20.01\n",
    "MobileNetV2 | 83.45      | 91.07 | 3.50\n",
    "EfficientNetB0 | 79.34    | 85.47 | 4.13\n",
    "Transformer | 94.61       | 98.56 | 85.87\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Training accuracy can be improved by increasing number of epoch. all the models are trained under epoch 15. and the training time is huge and the discontinuty proble of colab. So I trained it with very small epoch and weight decay. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMp3fcOvGEtT+wDT7w3SKgf",
   "collapsed_sections": [
    "AmwfhTApsVj9"
   ],
   "mount_file_id": "1k2icjSR786wYw1Lmd1T6ytMS9pQ0AYbq",
   "name": "Build_a_food_image_classifier.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
