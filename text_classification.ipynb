{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLeAgj0rAtSR",
        "outputId": "b92fa445-2a46-478a-9c41-219829d03fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "/content/data\n",
            "Archive:  /content/drive/MyDrive/dataset/IMDB_Dataset.csv.zip\n",
            "replace /content/data/IMDB Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "%mkdir data\n",
        "%cd data\n",
        "!unzip /content/drive/MyDrive/dataset/IMDB_Dataset.csv.zip -d /content/data/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQayuKbwBXIg",
        "outputId": "6a6c5f18-77bd-4a77-f85e-e84cb092d508"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import get_linear_schedule_with_warmup, AdamW, BertTokenizer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ],
      "metadata": {
        "id": "Q3BjppUKCHE8"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/data/IMDB Dataset.csv\")\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkeZHponDBB9",
        "outputId": "2e292f14-7ab9-4c25-f96e-ab8bda03cae7"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(df['sentiment']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x38bQPPgDGsH",
        "outputId": "57187a95-41ff-4ce4-f437-35ada1f8559c"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'negative', 'positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_id = {\n",
        "    'negative' : 0, \n",
        "    'positive' : 1,\n",
        "}\n",
        "df['sentiment'] = df.sentiment.map(class_to_id)"
      ],
      "metadata": {
        "id": "4eGEbwEDdqp5"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(df['sentiment']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8v5TFrHeAIp",
        "outputId": "bea7a7f1-cf81-42cd-acd7-a05d462c80b7"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = df.review.values\n",
        "labels = df.sentiment.values"
      ],
      "metadata": {
        "id": "haXV-8Z2DSCx"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    do_lower_case = True\n",
        ")"
      ],
      "metadata": {
        "id": "5NilD4SwDha6"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(text[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTlQ3EtjD84b",
        "outputId": "17131b70-34e5-4bae-f562-9b5d6f959d31"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['phil',\n",
              " 'the',\n",
              " 'alien',\n",
              " 'is',\n",
              " 'one',\n",
              " 'of',\n",
              " 'those',\n",
              " 'qui',\n",
              " '##rky',\n",
              " 'films',\n",
              " 'where',\n",
              " 'the',\n",
              " 'humour',\n",
              " 'is',\n",
              " 'based',\n",
              " 'around',\n",
              " 'the',\n",
              " 'odd',\n",
              " '##ness',\n",
              " 'of',\n",
              " 'everything',\n",
              " 'rather',\n",
              " 'than',\n",
              " 'actual',\n",
              " 'punch',\n",
              " '##lines',\n",
              " '.',\n",
              " '<',\n",
              " 'br',\n",
              " '/',\n",
              " '>',\n",
              " '<',\n",
              " 'br',\n",
              " '/',\n",
              " '>',\n",
              " 'at',\n",
              " 'first',\n",
              " 'it',\n",
              " 'was',\n",
              " 'very',\n",
              " 'odd',\n",
              " 'and',\n",
              " 'pretty',\n",
              " 'funny',\n",
              " 'but',\n",
              " 'as',\n",
              " 'the',\n",
              " 'movie',\n",
              " 'progressed',\n",
              " 'i',\n",
              " 'didn',\n",
              " \"'\",\n",
              " 't',\n",
              " 'find',\n",
              " 'the',\n",
              " 'jokes',\n",
              " 'or',\n",
              " 'odd',\n",
              " '##ness',\n",
              " 'funny',\n",
              " 'anymore',\n",
              " '.',\n",
              " '<',\n",
              " 'br',\n",
              " '/',\n",
              " '>',\n",
              " '<',\n",
              " 'br',\n",
              " '/',\n",
              " '>',\n",
              " 'its',\n",
              " 'a',\n",
              " 'low',\n",
              " 'budget',\n",
              " 'film',\n",
              " '(',\n",
              " 'that',\n",
              " '##s',\n",
              " 'never',\n",
              " 'a',\n",
              " 'problem',\n",
              " 'in',\n",
              " 'itself',\n",
              " ')',\n",
              " ',',\n",
              " 'there',\n",
              " 'were',\n",
              " 'some',\n",
              " 'pretty',\n",
              " 'interesting',\n",
              " 'characters',\n",
              " ',',\n",
              " 'but',\n",
              " 'eventually',\n",
              " 'i',\n",
              " 'just',\n",
              " 'lost',\n",
              " 'interest',\n",
              " '.',\n",
              " '<',\n",
              " 'br',\n",
              " '/',\n",
              " '>',\n",
              " '<',\n",
              " 'br',\n",
              " '/',\n",
              " '>',\n",
              " 'i',\n",
              " 'imagine',\n",
              " 'this',\n",
              " 'film',\n",
              " 'would',\n",
              " 'appeal',\n",
              " 'to',\n",
              " 'a',\n",
              " 'stone',\n",
              " '##r',\n",
              " 'who',\n",
              " 'is',\n",
              " 'currently',\n",
              " 'part',\n",
              " '##aking',\n",
              " '.',\n",
              " '<',\n",
              " 'br',\n",
              " '/',\n",
              " '>',\n",
              " '<',\n",
              " 'br',\n",
              " '/',\n",
              " '>',\n",
              " 'for',\n",
              " 'something',\n",
              " 'similar',\n",
              " 'but',\n",
              " 'better',\n",
              " 'try',\n",
              " '\"',\n",
              " 'brother',\n",
              " 'from',\n",
              " 'another',\n",
              " 'planet',\n",
              " '\"']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[10]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P2q_3hcENTk",
        "outputId": "d0923506-bc1a-4287-c71f-74e672749208"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6316,\n",
              " 1996,\n",
              " 7344,\n",
              " 2003,\n",
              " 2028,\n",
              " 1997,\n",
              " 2216,\n",
              " 21864,\n",
              " 15952,\n",
              " 3152,\n",
              " 2073,\n",
              " 1996,\n",
              " 17211,\n",
              " 2003,\n",
              " 2241,\n",
              " 2105,\n",
              " 1996,\n",
              " 5976,\n",
              " 2791,\n",
              " 1997,\n",
              " 2673,\n",
              " 2738,\n",
              " 2084,\n",
              " 5025,\n",
              " 8595,\n",
              " 12735,\n",
              " 1012,\n",
              " 1026,\n",
              " 7987,\n",
              " 1013,\n",
              " 1028,\n",
              " 1026,\n",
              " 7987,\n",
              " 1013,\n",
              " 1028,\n",
              " 2012,\n",
              " 2034,\n",
              " 2009,\n",
              " 2001,\n",
              " 2200,\n",
              " 5976,\n",
              " 1998,\n",
              " 3492,\n",
              " 6057,\n",
              " 2021,\n",
              " 2004,\n",
              " 1996,\n",
              " 3185,\n",
              " 12506,\n",
              " 1045,\n",
              " 2134,\n",
              " 1005,\n",
              " 1056,\n",
              " 2424,\n",
              " 1996,\n",
              " 13198,\n",
              " 2030,\n",
              " 5976,\n",
              " 2791,\n",
              " 6057,\n",
              " 4902,\n",
              " 1012,\n",
              " 1026,\n",
              " 7987,\n",
              " 1013,\n",
              " 1028,\n",
              " 1026,\n",
              " 7987,\n",
              " 1013,\n",
              " 1028,\n",
              " 2049,\n",
              " 1037,\n",
              " 2659,\n",
              " 5166,\n",
              " 2143,\n",
              " 1006,\n",
              " 2008,\n",
              " 2015,\n",
              " 2196,\n",
              " 1037,\n",
              " 3291,\n",
              " 1999,\n",
              " 2993,\n",
              " 1007,\n",
              " 1010,\n",
              " 2045,\n",
              " 2020,\n",
              " 2070,\n",
              " 3492,\n",
              " 5875,\n",
              " 3494,\n",
              " 1010,\n",
              " 2021,\n",
              " 2776,\n",
              " 1045,\n",
              " 2074,\n",
              " 2439,\n",
              " 3037,\n",
              " 1012,\n",
              " 1026,\n",
              " 7987,\n",
              " 1013,\n",
              " 1028,\n",
              " 1026,\n",
              " 7987,\n",
              " 1013,\n",
              " 1028,\n",
              " 1045,\n",
              " 5674,\n",
              " 2023,\n",
              " 2143,\n",
              " 2052,\n",
              " 5574,\n",
              " 2000,\n",
              " 1037,\n",
              " 2962,\n",
              " 2099,\n",
              " 2040,\n",
              " 2003,\n",
              " 2747,\n",
              " 2112,\n",
              " 15495,\n",
              " 1012,\n",
              " 1026,\n",
              " 7987,\n",
              " 1013,\n",
              " 1028,\n",
              " 1026,\n",
              " 7987,\n",
              " 1013,\n",
              " 1028,\n",
              " 2005,\n",
              " 2242,\n",
              " 2714,\n",
              " 2021,\n",
              " 2488,\n",
              " 3046,\n",
              " 1000,\n",
              " 2567,\n",
              " 2013,\n",
              " 2178,\n",
              " 4774,\n",
              " 1000]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "  def __init__(self, texts, targets, max_len=32):\n",
        "    self.data = texts\n",
        "    self.targets = targets\n",
        "    self.tokenizer = BertTokenizer.from_pretrained(\n",
        "        \"bert-base-uncased\",\n",
        "        do_lower_case = True\n",
        "    )\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    text = str(self.data[idx])\n",
        "    inputs = self.tokenizer(\n",
        "        text,\n",
        "        None, \n",
        "        add_special_tokens = True,\n",
        "        max_length = self.max_len,\n",
        "        padding=\"max_length\",\n",
        "        return_attention_mask = True,\n",
        "        truncation = True,\n",
        "        # return_tensors = 'pt'\n",
        "    )\n",
        "\n",
        "    response = {\n",
        "        \"ids\": torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
        "        \"mask\": torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
        "        \"token_type_ids\": torch.tensor(inputs['token_type_ids'], dtype=torch.long),\n",
        "        \"targets\": torch.tensor(self.targets[idx], dtype=torch.long)\n",
        "    }\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "SULh-bXiL9fG"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Base_Model(nn.Module):\n",
        "\n",
        "    def __init__(self, bert_config='bert-base-uncased', \n",
        "                n_class=2, drop_out=0.2):\n",
        "      \n",
        "        super(Base_Model, self).__init__()\n",
        "        self.bert_config = bert_config\n",
        "        self.bert = BertModel.from_pretrained(self.bert_config)\n",
        "        self.bert_drop = nn.Dropout(drop_out)\n",
        "        self.out = nn.Linear(768, n_class)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "\n",
        "        output = self.bert(\n",
        "            ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
        "        # output = self.bert_drop(output)\n",
        "        return self.out(output['pooler_output'])"
      ],
      "metadata": {
        "id": "6rEJRq3DKDPb"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = BERTDataset(texts = text, targets = labels, max_len = 32)"
      ],
      "metadata": {
        "id": "ZIVrEY0oRy6R"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(data)).tolist()\n",
        "split_idx = int(0.2 * len(data))\n",
        "\n",
        "trainset = torch.utils.data.Subset(data, indices[:-split_idx])\n",
        "valset = torch.utils.data.Subset(data, indices[-split_idx:])\n",
        "print(\"Total no.\", len(data), len(trainset), len(valset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkT3EFF8V5gO",
        "outputId": "fbe641c3-dd3a-4e35-e514-314abe6a4e88"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no. 50000 40000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 40\n",
        "pretrain_warmup_steps = 30\n",
        "learn_r = 3e-5\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "xUtNj1dNS2AV"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "iKx9VP_7WKjH"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Base_Model(bert_config='bert-base-uncased', n_class=2)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-RB7sw4TIVb",
        "outputId": "02f2db91-727f-4839-f11b-d542411c8496"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Base_Model(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (bert_drop): Dropout(p=0.2, inplace=False)\n",
              "  (out): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_training_steps = int(len(trainset) / batch_size * epochs)\n",
        "optimizer=AdamW(model.parameters(), lr=learn_r)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps = 0,\n",
        "    num_training_steps = num_training_steps\n",
        ")\n",
        "\n",
        "loss_fun = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ZwtPIVKKTAQ8"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device='cuda'"
      ],
      "metadata": {
        "id": "fA6alb2aW4Cz"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    val_acc_track = 0.0\n",
        "    current_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(train_loader, unit=\"batch\") as tloader:\n",
        "        for batch in tloader:\n",
        "            \n",
        "            tloader.set_description(\"Epoch {}\".format(epoch))\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            ids = batch[\"ids\"].to(device)\n",
        "            ids= ids.squeeze(1)\n",
        "\n",
        "            mask = batch['mask'].to(device) \n",
        "            token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "            targets = batch[\"targets\"].to(device)    \n",
        "            outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "\n",
        "            loss = loss_fun(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            current_loss += loss.item()\n",
        "            tloader.set_postfix(loss=loss.item())\n",
        "\n",
        "    train_loss = current_loss/len(train_loader)\n",
        "    print(\"Training Epoch {}, Training Loss {}\".format(epoch, train_loss))\n",
        "\n",
        "    model.eval()\n",
        "    current_loss = 0.0\n",
        "\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        with tqdm(val_loader, unit=\"batch\") as tloader:\n",
        "            for batch in tloader:\n",
        "\n",
        "                tloader.set_description(\"Epoch {}\".format(epoch))\n",
        "\n",
        "                ids = batch[\"ids\"].to(device)\n",
        "                mask = batch['mask'].to(device) \n",
        "                token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "                targets = batch[\"targets\"].to(device)  \n",
        "\n",
        "                outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "\n",
        "                loss = loss_fun(outputs, targets)\n",
        "                current_loss += loss.item()\n",
        "                tloader.set_postfix(loss=loss.item())\n",
        "\n",
        "                _, pred = torch.max(outputs.data, 1)\n",
        "\n",
        "                fin_targets.append(targets.cpu().detach().numpy())\n",
        "                fin_outputs.append(pred.cpu().detach().numpy())\n",
        "\n",
        "    val_loss = current_loss/len(val_loader)\n",
        "    print(\"val epoch {}, val Loss {}\".format(epoch, val_loss))\n",
        "    target = np.concatenate(fin_targets)\n",
        "    predicted = np.concatenate(fin_outputs)\n",
        "    accuracy = accuracy_score(predicted, target)\n",
        "    print(\"Accuracy {}\".format(accuracy))\n",
        "    if accuracy > val_acc_track:\n",
        "        ckpt = {\n",
        "            'model_dict': model.state_dict(),\n",
        "            'optim_dict': optimizer.state_dict(),\n",
        "            'eval_loss': val_loss,\n",
        "            'accuracy': accuracy\n",
        "        }\n",
        "\n",
        "        \n",
        "        save_path = 'best_model.pt'\n",
        "        torch.save(ckpt, save_path)\n",
        "        val_acc_track = accuracy"
      ],
      "metadata": {
        "id": "BlEF1z7lT56H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"https://www.kaggle.com/code/jaskaransingh/bert-fine-tuning-with-pytorch\")\n",
        "print(\"https://luv-bansal.medium.com/fine-tuning-bert-for-text-classification-in-pytorch-503d97342db2\")\n",
        "print(\"https://www.kaggle.com/code/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews/notebook\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGY2e-MVYrpX",
        "outputId": "d3bfd56f-551b-449f-a597-61ca6d2a5afc"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.kaggle.com/code/jaskaransingh/bert-fine-tuning-with-pytorch\n",
            "https://luv-bansal.medium.com/fine-tuning-bert-for-text-classification-in-pytorch-503d97342db2\n",
            "https://www.kaggle.com/code/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews/notebook\n"
          ]
        }
      ]
    }
  ]
}